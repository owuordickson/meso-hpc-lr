{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Read all results from txt files\n",
    "\n",
    "grad_path = \"./raw_files/GRAD/\"\n",
    "grad_files = [f for f in listdir(grad_path) if isfile(join(grad_path, f))]\n",
    "\n",
    "gradl_path = \"./raw_files/GRAD_L/\"\n",
    "gradl_files = [f for f in listdir(gradl_path) if isfile(join(gradl_path, f))]\n",
    "\n",
    "gradh5_path = \"./raw_files/GRAD_H5/\"\n",
    "gradh5_files = [f for f in listdir(gradh5_path) if isfile(join(gradh5_path, f))]\n",
    "\n",
    "# GRAD Algorithm\n",
    "\n",
    "column_names = [\"Data-set\", \"Size\", \"Algorithm\", \"Support\", \"Run-time\", \"Memory\", \"Patterns\"]\n",
    "\n",
    "df_grad = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n",
    "for file in grad_files:\n",
    "    f_path = join(grad_path,file)\n",
    "    res = pd.read_csv(f_path, sep = ': ', header=None, engine='python', nrows=8)\n",
    "    run = float(res[1][0][0:6]) # run-time\n",
    "    mem = float(res[1][1][0:5]) # memory\n",
    "    pat = float(res[1][7]) # patterns\n",
    "    alg = res[1][2] # algorithm\n",
    "    att = int(res[1][3]) # number of attributes in the data set\n",
    "    sup = float(res[1][5]) # minimum support\n",
    "    size = int(res[1][4])  # data set size\n",
    "\n",
    "\n",
    "\n",
    "    if att == 98:\n",
    "        col = \"C2K\"\n",
    "    elif att == 9:\n",
    "        col = \"UCI\"\n",
    "    else:\n",
    "        col = \"\"\n",
    "            \n",
    "    df_grad = df_grad.append({\"Data-set\": col, \"Size\": size, \"Algorithm\":alg, \"Support\": sup, \"Run-time\":run, \"Memory\":mem, \"Patterns\":pat}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "# GRAD-H5 Algorithm\n",
    "# column_names = [\"Data-set\", \"Algorithm\", \"Support\", \"Run-time\", \"Memory\", \"Patterns\"]\n",
    "\n",
    "df_gradh5 = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n",
    "for file in gradh5_files:\n",
    "    f_path = join(gradh5_path,file)\n",
    "    res = pd.read_csv(f_path, sep = ': ', header=None, engine='python', nrows=11)\n",
    "    run = float(res[1][0][0:6]) # run-time\n",
    "    mem = float(res[1][1][0:5]) # memory\n",
    "    pat = float(res[1][10]) # patterns\n",
    "    alg = res[1][2] # algorithm\n",
    "    att = int(res[1][5]) # number of attributes in the data set\n",
    "    sup = float(res[1][3]) # minimum support\n",
    "    size = int(res[1][6])  # data set size\n",
    "\n",
    "\n",
    "\n",
    "    if att == 98:\n",
    "        col = \"C2K\"\n",
    "    elif att == 9:\n",
    "        col = \"UCI\"\n",
    "    else:\n",
    "        col = \"\"\n",
    "            \n",
    "    df_gradh5 = df_gradh5.append({\"Data-set\": col, \"Size\": size, \"Algorithm\":alg, \"Support\": sup, \"Run-time\":run, \"Memory\":mem, \"Patterns\":pat}, ignore_index=True)\n",
    "\n",
    "\n",
    "    \n",
    "#GRAD-L Algorithm\n",
    "\n",
    "column_names = [\"Data-set\", \"Size\", \"Algorithm\", \"Support\", \"Chunk-size\", \"Run-time\", \"Memory\", \"Patterns\"]\n",
    "\n",
    "df_gradl = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n",
    "for file in gradl_files:\n",
    "    f_path = join(gradl_path,file)\n",
    "    res = pd.read_csv(f_path, sep = ': ', header=None, engine='python', nrows=12)\n",
    "    run = float(res[1][0][0:6]) # run-time\n",
    "    mem = float(res[1][1][0:5]) # memory\n",
    "    pat = float(res[1][11]) # patterns\n",
    "    alg = res[1][2] # algorithm\n",
    "    att = int(res[1][5]) # number of attributes in the data set\n",
    "    sup = float(res[1][3]) # minimum support\n",
    "    size = int(res[1][6])  # data set size\n",
    "    chk = int(res[1][7])  # chunk size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if att == 98:\n",
    "        col = \"C2K\"\n",
    "    elif att == 9:\n",
    "        col = \"UCI\"\n",
    "    else:\n",
    "        col = \"\"\n",
    "            \n",
    "    df_gradl = df_gradl.append({\"Data-set\": col, \"Size\": size, \"Algorithm\":alg, \"Support\": sup, \"Chunk-size\": chk, \"Run-time\":run, \"Memory\":mem, \"Patterns\":pat}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all results into one data-frame\n",
    "\n",
    "frames = [df_grad, df_gradh5, df_gradl]\n",
    "df_res = pd.concat(frames)\n",
    "# df_res\n",
    "\n",
    "# Describing the results\n",
    "\n",
    "# df_res.groupby([\"Data-set\", \"Support\", \"Algorithm\"]).describe().to_excel(\"stats.xlsx\", sheet_name=\"Stats\")\n",
    "# df_res.groupby([\"Data-set\", \"Size\", \"Algorithm\"]).describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore these columns\n",
    "# df_res = df_res.drop(['Support', 'Chunk-size'], axis=1)\n",
    "df_res2 = df_res[['Data-set', 'Size', 'Algorithm', 'Run-time', 'Patterns', 'Memory']]\n",
    "\n",
    "df = df_res2.groupby([\"Data-set\", \"Size\", \"Algorithm\"])#.describe(percentiles=[])\n",
    "df2 = pd.concat([df.min(), df.mean(), df.max(), df.std()], keys=['min', 'mean', 'max', 'std'], axis=1)\n",
    "#df2.filter(like=\"Run-time\")\n",
    "df2.columns = df2.columns.swaplevel(0, 1)\n",
    "df2.sort_index(axis=1, level=0, inplace=True, ascending=False)\n",
    "df2.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-system",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
